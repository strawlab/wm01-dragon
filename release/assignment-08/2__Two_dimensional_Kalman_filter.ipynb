{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating two dimensional state (position and velocity) with single dimension observation\n",
    "\n",
    "Now that we have some experience with multi-variate normals, let's expand our use of the Kalman filter from 1D to 2D. This example will be very similar to the previous example, but now we will use a 2D state model:\n",
    "\n",
    "$x_{t+1} = x_t + dt \\cdot y_t + noise$\n",
    "\n",
    "$y_{t+1} = y_t + noise$\n",
    "\n",
    "This is a \"constant velocity\" motion model. We model the velocity ($y$ here) as being constant plus noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import adskalman.adskalman as adskalman\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(arr):\n",
    "    \"\"\"convert 1D array-like to a 2D vertical array\n",
    "\n",
    "    >>> column((1,2,3))\n",
    "\n",
    "    array([[1],\n",
    "           [2],\n",
    "           [3]])\n",
    "    \"\"\"\n",
    "    arr = np.array(arr)\n",
    "    assert arr.ndim == 1\n",
    "    a2 = arr[:, np.newaxis]\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2-dimensional state space model:\n",
    "# (x, xvel).\n",
    "dt = 0.01\n",
    "true_initial_state = column([0.0, 10.0])\n",
    "# This is F in wikipedia language.\n",
    "motion_model = np.array([[1.0, dt],\n",
    "                         [0.0, 1.0]])\n",
    "\n",
    "# This is Q in wikipedia language. For a constant velocity form, \n",
    "# it must take this specific form to be correct. The\n",
    "# only free parameter here is `motion_noise_scale`.\n",
    "motion_noise_scale = 1000.0\n",
    "\n",
    "# Do not change these values\n",
    "T3 = dt**3/3\n",
    "T2 = dt**2/2\n",
    "motion_noise_covariance = motion_noise_scale*np.array([[T3, T2],\n",
    "                                           [T2, dt]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 0.5\n",
    "t = np.arange(0.0, duration, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some fake data with our model.\n",
    "current_state = true_initial_state\n",
    "state = []\n",
    "for _ in t:\n",
    "    state.append(current_state[:, 0])\n",
    "    noise_sample = adskalman.rand_mvn(np.zeros(2), motion_noise_covariance, 1).T\n",
    "    current_state = np.dot(motion_model, current_state) + noise_sample\n",
    "state = np.array(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(state[:, 0], '.-', label='true x')\n",
    "ax.legend()\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(state[:, 1], '.-', label='true x vel')\n",
    "ax.legend()\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x vel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create observation model. We can only observe position.\n",
    "observation_model = np.array([[1.0, 0.0]])\n",
    "observation_noise_covariance = np.array([[0.01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create noisy observations.\n",
    "observation = []\n",
    "for current_state in state:\n",
    "    noise_sample = adskalman.rand_mvn(np.zeros(1), observation_noise_covariance, 1).T\n",
    "    current_observation = np.dot(observation_model, column(current_state)) + noise_sample\n",
    "    observation.append(current_observation[:, 0])\n",
    "observation = np.array(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(observation[:, 0], '.-', label='observation')\n",
    "plt.legend()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run kalman filter on the noisy observations.\n",
    "y = observation\n",
    "F = motion_model\n",
    "H = observation_model\n",
    "Q = motion_noise_covariance\n",
    "R = observation_noise_covariance\n",
    "initx = true_initial_state[:, 0]\n",
    "initV = 0.1*np.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfilt = adskalman.KalmanFilter(F, H, Q, R, initx, initV)\n",
    "xfilt = []\n",
    "Vfilt = []\n",
    "for i, y_i in enumerate(y):\n",
    "    is_initial = i == 0\n",
    "    xfilt_i, Vfilt_i = kfilt.step(y=y_i, isinitial=is_initial)\n",
    "    xfilt.append(xfilt_i)\n",
    "    Vfilt.append(Vfilt_i)\n",
    "xfilt = np.array(xfilt)\n",
    "Vfilt = np.array(Vfilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(10,8))\n",
    "\n",
    "ax = axs[0]\n",
    "t = np.arange(len(xfilt[:, 0]))\n",
    "low = xfilt[:, 0]-np.sqrt(Vfilt[:, 0, 0])\n",
    "high = xfilt[:, 0]+np.sqrt(Vfilt[:, 0, 0])\n",
    "ax.fill_between(t, low, high, alpha=0.2, color='green')\n",
    "\n",
    "ax.plot(t,state[:, 0], '.-', label='true')\n",
    "ax.plot(t,observation[:, 0], '.-', label='observed')\n",
    "ax.plot(t,xfilt[:, 0], '.-', color='green', label='KF estimate')\n",
    "\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x')\n",
    "ax.legend()\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(Vfilt[:, 0, 0], '.-', label='variance')\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('$\\sigma^2$')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run again with missing data\n",
    "y[25:35, :] = np.nan\n",
    "kfilt = adskalman.KalmanFilter(F, H, Q, R, initx, initV)\n",
    "xfilt = []\n",
    "Vfilt = []\n",
    "for i, y_i in enumerate(y):\n",
    "    is_initial = i == 0\n",
    "    xfilt_i, Vfilt_i = kfilt.step(y=y_i, isinitial=is_initial)\n",
    "    xfilt.append(xfilt_i)\n",
    "    Vfilt.append(Vfilt_i)\n",
    "xfilt = np.array(xfilt)\n",
    "Vfilt = np.array(Vfilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(10,8))\n",
    "\n",
    "ax = axs[0]\n",
    "t = np.arange(len(xfilt[:, 0]))\n",
    "low = xfilt[:, 0]-np.sqrt(Vfilt[:, 0, 0])\n",
    "high = xfilt[:, 0]+np.sqrt(Vfilt[:, 0, 0])\n",
    "ax.fill_between(t, low, high, alpha=0.2, color='green')\n",
    "\n",
    "ax.plot(t,state[:, 0], '.-', label='true')\n",
    "ax.plot(t,observation[:, 0], '.-', label='observed')\n",
    "ax.plot(t,xfilt[:, 0], '.-', color='green', label='KF estimate')\n",
    "\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x')\n",
    "ax.legend()\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(Vfilt[:, 0, 0], '.-', label='variance')\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('$\\sigma^2$')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 Compared to our 1 dimensional state, we now do a much better job estimating the position, even when we have no observations. Why is that?\n",
    "\n",
    "(You answer should be a text explanation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb6649f0f0bd33413dba5eb9d18d3fae",
     "grade": true,
     "grade_id": "cell-a2bc0fa042093799",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to our better ability to estimate position, there is something else pretty interesting going on here. Although our observations are only positions, our estimates also include velocities. Given that the Kalman filter is the Bayesian optimal solution of a linear dynamic system with normally distributed noise, these velocity estimates are the best that can be done according to Bayes' theorem.\n",
    "\n",
    "Let's look at our velocity estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, figsize=(10,4))\n",
    "\n",
    "ax = axs\n",
    "t = np.arange(len(xfilt[:, 1]))\n",
    "low = xfilt[:, 1]-np.sqrt(Vfilt[:, 1, 0])\n",
    "high = xfilt[:, 1]+np.sqrt(Vfilt[:, 1, 0])\n",
    "ax.fill_between(t, low, high, alpha=0.2, color='green')\n",
    "\n",
    "ax.plot(t,state[:, 1], '.-', label='true')\n",
    "ax.plot(t,xfilt[:, 1], '.-', color='green', label='KD estimate')\n",
    "\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x vel')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we measuring position and then calculating velocity, we take the naive approach and simply measure the difference between adjacent time points and scale by the time interval. What would that look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = observation[1:, 0] - observation[:-1, 0]\n",
    "naive = dy/dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, figsize=(10,4))\n",
    "\n",
    "ax = axs\n",
    "t = np.arange(len(xfilt[:, 1]))\n",
    "low = xfilt[:, 1]-np.sqrt(Vfilt[:, 1, 0])\n",
    "high = xfilt[:, 1]+np.sqrt(Vfilt[:, 1, 0])\n",
    "ax.fill_between(t, low, high, alpha=0.2, color='green')\n",
    "\n",
    "ax.plot(t,state[:, 1], '.-', label='true')\n",
    "ax.plot(t,xfilt[:, 1], '.-', color='green', label='KF estimate')\n",
    "ax.plot(t[1:],naive, '.-', color='red', label='naive')\n",
    "\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x vel')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our estimate from the Kalman filter is not only much closer to the true value, it also has the advantage that we have some estimate even for the periods in which we have no observations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
